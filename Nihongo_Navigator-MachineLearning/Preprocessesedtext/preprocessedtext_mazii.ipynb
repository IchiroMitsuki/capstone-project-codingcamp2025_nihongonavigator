{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d2901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.data.path.append(r\"C:\\Users\\User\\AppData\\Roaming\\nltk_data\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0718471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RevMazii = pd.read_csv(r\"C:\\Latihan_Python\\casptone-project-dicoding_nihongonavigator\\ulasan_Mazii.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04947a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2725\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "jumlah_ulasan, jumlah_kolom = df_RevMazii.shape\n",
    "\n",
    "print(jumlah_ulasan)\n",
    "print(jumlah_kolom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa29e70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pada fitur terjemahan dengan gambar, hampir se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tolong hapus iklan di bawah nyaaa, itu sangat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aplikasi nya bagus dan kalau bisa mohon jadika...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>overall buat latihan kanji atau kotoba nya oke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setelah beberapa hari premium seumur hidup lal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  pada fitur terjemahan dengan gambar, hampir se...\n",
       "1  Tolong hapus iklan di bawah nyaaa, itu sangat ...\n",
       "2  aplikasi nya bagus dan kalau bisa mohon jadika...\n",
       "3  overall buat latihan kanji atau kotoba nya oke...\n",
       "4  setelah beberapa hari premium seumur hidup lal..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RevMazii.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92efc49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2725 entries, 0 to 2724\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  2725 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 21.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_RevMazii.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d39b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Missing Value\n",
      "Review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah Missing Value\")\n",
    "print(df_RevMazii.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2e329d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Duplikat Value\n",
      "822\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah Duplikat Value\")\n",
    "print(df_RevMazii.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ef75877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_RevMazii_clean = df_RevMazii.drop_duplicates()\n",
    "print(df_RevMazii_clean.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96e6fbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pada fitur terjemahan dengan gambar, hampir se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tolong hapus iklan di bawah nyaaa, itu sangat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aplikasi nya bagus dan kalau bisa mohon jadika...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>overall buat latihan kanji atau kotoba nya oke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setelah beberapa hari premium seumur hidup lal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  pada fitur terjemahan dengan gambar, hampir se...\n",
       "1  Tolong hapus iklan di bawah nyaaa, itu sangat ...\n",
       "2  aplikasi nya bagus dan kalau bisa mohon jadika...\n",
       "3  overall buat latihan kanji atau kotoba nya oke...\n",
       "4  setelah beberapa hari premium seumur hidup lal..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RevMazii_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e56a0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1903 entries, 0 to 2719\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1903 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 29.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_RevMazii_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97479d7",
   "metadata": {},
   "source": [
    "## **Text PreProcessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "781e1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
    "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "\n",
    "\n",
    "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
    "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "def filteringText(text): # Menghapus stopwords dalam teks\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    listStopwords1 = set(stopwords.words('english'))\n",
    "    listStopwords.update(listStopwords1)\n",
    "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku',\"di\",\"ga\",\"ya\",\"gaa\",\"loh\",\"kah\",\"woi\",\"woii\",\"woy\", \"wkwk\", \"uuu\"])\n",
    "    important_words = {'baik', 'buruk', 'mantap', 'bagus', 'jelek', 'mudah', 'cepat', 'nyaman'} #Bisa ditambah\n",
    "    # Hapus kata penting dari daftar stopwords\n",
    "    listStopwords = listStopwords - important_words\n",
    "\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    "\n",
    "def stemmingText(text): # Mengurangi kata ke bentuk dasarnya yang menghilangkan imbuhan awalan dan akhiran atau ke akar kata\n",
    "    # Membuat objek stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    # Memecah teks menjadi daftar kata\n",
    "    words = text.split()\n",
    "\n",
    "    # Menerapkan stemming pada setiap kata dalam daftar\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Menggabungkan kata-kata yang telah distem\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return stemmed_text\n",
    "\n",
    "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15556414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7an -> tujuan\n",
      "@ -> di\n",
      "ababil -> anak ingusan\n",
      "abis -> habis\n",
      "acc -> accord\n",
      "ad -> ada\n",
      "adlah -> adalah\n",
      "adlh -> adalah\n",
      "adoh -> aduh\n",
      "afaik -> as far as i know\n"
     ]
    }
   ],
   "source": [
    "def load_slang_dictionary():\n",
    "    slangwords = {}\n",
    "\n",
    "    def read_file(path, delimiter):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if delimiter not in line or not line:\n",
    "                    continue  # lewati baris yang kosong atau tidak valid\n",
    "                parts = line.split(delimiter, 1)\n",
    "                if len(parts) != 2:\n",
    "                    continue  # lewati jika tetap gagal dibagi jadi 2\n",
    "                key, value = parts\n",
    "                if key and value:\n",
    "                    slangwords[key.lower()] = value.lower()\n",
    "\n",
    "    # Gabungkan dari semua file\n",
    "    read_file(r'C:\\Latihan_Python\\@-proyek-course-dicoding\\proyek_analisis_sentimen\\Indonesian Slang dictionary (from github)\\formalizationDict.txt', '\\t')\n",
    "    read_file(r'C:\\Latihan_Python\\@-proyek-course-dicoding\\proyek_analisis_sentimen\\Indonesian Slang dictionary (from github)\\kbba.txt', '\\t')\n",
    "    read_file(r'C:\\Latihan_Python\\@-proyek-course-dicoding\\proyek_analisis_sentimen\\Indonesian Slang dictionary (from github)\\slangword.txt', ':')\n",
    "\n",
    "    return slangwords\n",
    "\n",
    "# Panggil fungsi\n",
    "slangwords = load_slang_dictionary()\n",
    "\n",
    "# Contoh tampilkan 10 kata\n",
    "for i, (k, v) in enumerate(slangwords.items()):\n",
    "    if i >= 10: break\n",
    "    print(f\"{k} -> {v}\")\n",
    "\n",
    "def fix_slangwords(text, slang_dict):\n",
    "    words = text.split()  # Memecah teks jadi list kata\n",
    "    fixed_words = [slang_dict.get(word.lower(), word) for word in words]  # Ganti jika ada di kamus\n",
    "    return ' '.join(fixed_words)  # Gabung kembali jadi kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "036b6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_heuristic(text):\n",
    "    # Ganti koma dan kata penghubung umum dengan titik\n",
    "    text = re.sub(r'\\s*(,|namun|tapi|tetapi|meskipun|walaupun|serta)\\s*', '.', text)\n",
    "    \n",
    "    # Pisah berdasarkan titik atau baris baru\n",
    "    sentences = re.split(r'\\.|\\n', text)\n",
    "\n",
    "    # Bersihkan hasil\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 3]\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ac52441",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_normalization = {\n",
    "    \"mantaaap\": \"mantap\",\n",
    "    \"bangett\": \"banget\",\n",
    "    \"kerenn\": \"keren\",\n",
    "    \"prem\": \"premium\",\n",
    "    \"bagusss\": \"bagus\",\n",
    "    \"membantuuu\": \"membantu\",\n",
    "    \"bangettt\": \"banget\",\n",
    "    \"bingunggg\": \"bingung\",\n",
    "    \"sangattt\": \"sangat\",\n",
    "    \"waaaah\": \"wah\",\n",
    "    \"polll\": \"pol\",           \n",
    "    \"tulisannnya\": \"tulisannya\",\n",
    "    \"maziiini\": \"mazii ini\",\n",
    "    \"salahhadehhhh\": \"salah hadeh\",\n",
    "    \"sangaatttt\": \"sangat\",\n",
    "    \"lagiii\": \"lagi\",\n",
    "    \"bagusssss\": \"bagus\",\n",
    "    \"bagusssbisa\": \"bagus bisa\",\n",
    "    \"mantaaapberjamjam\": \"mantap berjam-jam\",\n",
    "    \"waaaaah\": \"wah\",\n",
    "    \"yaaa\": \"ya\",\n",
    "    \"mmmmungkin\": \"mungkin\",\n",
    "    \"bagussss\": \"bagus\",\n",
    "    \"mantappppuuu\": \"mantap\",\n",
    "    \"majuuu\": \"maju\",\n",
    "    \"bagussssss\": \"bagus\",\n",
    "    \"akuuu\": \"aku\",\n",
    "    \"hehheee\": \"hehe\",\n",
    "    \"kerennnn\": \"keren\",\n",
    "    \"makasiii\": \"makasih\",\n",
    "    \"gimanasi\": \"bagaimana sih\",\n",
    "    \"arigato\": \"terima kasih\",\n",
    "    \"arigatou\": \"terima kasih\",\n",
    "    \"radical\": \"radikal\",\n",
    "    \"knji\": \"kanji\",\n",
    "    \"knj\": \"kanji\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f13bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tokens(tokens, norm_dict):\n",
    "    return [norm_dict.get(word, word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b2458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_clean'] = df_RevMazii_clean['Review'].apply(cleaningText)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_casefoldingText'] = df_RevMazii_clean['text_clean'].apply(casefoldingText)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_final_splitted'] = df_RevMazii_clean['text_casefoldingText'].apply(split_heuristic).apply(toSentence)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_slangwords'] = df_RevMazii_clean['text_final_splitted'].apply(lambda x: fix_slangwords(x, slangwords))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_tokenizingText'] = df_RevMazii_clean['text_slangwords'].apply(tokenizingText)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_normalized'] = df_RevMazii_clean['text_tokenizingText'].apply(lambda x: normalize_tokens(x, custom_normalization))#Baru\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_stopword'] = df_RevMazii_clean['text_normalized'].apply(filteringText)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_sentenced'] = df_RevMazii_clean['text_stopword'].apply(toSentence)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13540\\2545808949.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RevMazii_clean['text_final_stemmed'] = df_RevMazii_clean['text_sentenced'].apply(stemmingText)\n"
     ]
    }
   ],
   "source": [
    "# Membersihkan teks dan menyimpannya di kolom 'text_clean'\n",
    "df_RevMazii_clean['text_clean'] = df_RevMazii_clean['Review'].apply(cleaningText)\n",
    "\n",
    "# Mengubah huruf dalam teks menjadi huruf kecil dan menyimpannya di 'text_casefoldingText'\n",
    "df_RevMazii_clean['text_casefoldingText'] = df_RevMazii_clean['text_clean'].apply(casefoldingText)\n",
    "\n",
    "df_RevMazii_clean['text_final_splitted'] = df_RevMazii_clean['text_casefoldingText'].apply(split_heuristic).apply(toSentence)#Baru\n",
    "\n",
    "# Mengganti kata-kata slang dengan kata-kata standar dan menyimpannya di 'text_slangwords'\n",
    "df_RevMazii_clean['text_slangwords'] = df_RevMazii_clean['text_final_splitted'].apply(lambda x: fix_slangwords(x, slangwords))\n",
    "\n",
    "# Memecah teks menjadi token (kata-kata) dan menyimpannya di 'text_tokenizingText'\n",
    "df_RevMazii_clean['text_tokenizingText'] = df_RevMazii_clean['text_slangwords'].apply(tokenizingText)\n",
    "\n",
    "df_RevMazii_clean['text_normalized'] = df_RevMazii_clean['text_tokenizingText'].apply(lambda x: normalize_tokens(x, custom_normalization))#Baru\n",
    "\n",
    "# Menghapus kata-kata stop (kata-kata umum) dan menyimpannya di 'text_stopword'\n",
    "df_RevMazii_clean['text_stopword'] = df_RevMazii_clean['text_normalized'].apply(filteringText)\n",
    "\n",
    "# Menggabungkan token-token menjadi kalimat dan menyimpannya di 'text_akhir'\n",
    "df_RevMazii_clean['text_sentenced'] = df_RevMazii_clean['text_stopword'].apply(toSentence)\n",
    "\n",
    "df_RevMazii_clean['text_final_stemmed'] = df_RevMazii_clean['text_sentenced'].apply(stemmingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b965a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RevMazii_clean.to_csv(r\"C:\\Latihan_Python\\casptone-project-dicoding_nihongonavigator\\Preprocessesedtext\\review_mazii_processedtext.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
